# -*- coding: utf-8 -*-
"""CarStoriesWithOpenAI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1W0JL3u1mXeYghRRFDLyuxxAPGUzZTr4k

# Install Dependencies
"""

!pip install -q soundfile
!pip install --upgrade -q moviepy
!pip install -q yagmail
!pip install -q openai
!pip install -q pydub
!pip install -q ffmpeg
!pip install -q tiktok-uploader
!pip install -q duckduckgo-search
!!pip install -q opencv-python-headless

import os
import cv2

import time
import shutil
import requests
import random
import matplotlib.pyplot as plt
from google.colab import userdata
import soundfile as sf
from IPython.display import Audio
import numpy as np
import textwrap
import gc
import yagmail
import openai
from openai import OpenAI
from PIL import Image
from io import BytesIO
from pydub import AudioSegment
from moviepy.video.VideoClip import ImageClip
from moviepy.audio.io.AudioFileClip import AudioFileClip
from moviepy.video.compositing.CompositeVideoClip import CompositeVideoClip
from duckduckgo_search import DDGS

client = OpenAI(api_key=userdata.get('OpenAI'))
print("OpenAI API token saved in userdata")

"""# Come up with story idea


"""

def get_story_idea():
    prompt = """
# ROLE:
You are an edgy automotive content creator with deep knowledge of car culture, engineering quirks, internet memes, and enthusiast drama. You specialize in short-form video content that is provocative, opinionated, and funny.

# TASK:
Come up with a viral TikTok/Instagram video ideas. Each idea should be formatted as a JSON object with:
{
  "car": "the full name and year range of the car featured",
  "concept": "the hook or headline, 1 sentence long"
}
The idea should be short, controversial, or intriguing, and formatted as a video hook. Avoid generic car reviews. Think meme-worthy, spicy, internet-argument-fueling content.

# OUTPUT CHARACTERISTICS:
- Output a JSON object.
- Each object must have a "car" field with a year + model
- Each object must have a "concept" field with a dramatic or sarcastic headline
- Mention generation, model, and years
- DO NOT explain anything — just return the list of a JSON entry

# EXAMPLES:

## Example 1:
{
  "car": "2001–2004 Porsche 996",
  "concept": "Why the 996 is the most hated 911 (and why that’s dumb)"
}

"""

    story_prompt_messages = [{"role": "user", "content": prompt}]

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=story_prompt_messages,
        temperature=2.0,
        max_tokens=1000,
        top_p=0.95,
        frequency_penalty=1.0,
        presence_penalty=0.5,
        n=1,
        response_format={"type": "json_object"}
    )

    # Parse the JSON output
    import json
    try:
        ideas = json.loads(response.choices[0].message.content)
        #selected = random.choice(ideas)
        return ideas
        #return selected  # returns a dict like {"car": "...", "concept": "..."}
    except Exception as e:
        print("Failed to parse story idea:", e)
        print("Raw output:", response.choices[0].message.content)
        return None

idea = get_story_idea()
print(idea)

"""# Write Story"""

def get_story(concept):
  prompt = f"""
# ROLE:
You are an edgy automotive content writer who creates viral short-form video scripts for TikTok and Instagram. You combine car knowledge, humor, and controversy to keep car enthusiasts engaged for 60 seconds or less.

# TASK:
Write a 60-second video script based on the following concept: "{concept}". Use a direct, opinionated tone. Keep the pacing fast and structured to retain attention:
- Hook (first line should grab attention)
- Drama / conflict / unusual fact
- Breakdown of why it matters
- Punchline, twist, or unexpected takeaway
- Optional call to action (“Would you buy this?” or “Follow for more car drama.”)

# Output Characteristics:
- Write it in first-person narrator voice
- Use short sentences and casual tone
- Include subtle humor or sarcasm
- Assume video will be paired with images/video clips of the car
- Max ~250 words (aim for 60-second voiceover timing)
- Do NOT add hashtags, emojis, or video editing instructions
- Kind of roast the car but actually hype the car up!

# Examples:
Concept: "Why the Porsche 996 sucks"
Script:
The Porsche 996 is the most hated 911 ever made.
It showed up with headlights that looked like scrambled eggs and an interior that felt cheaper than a 90s Corolla.
But the real kicker? The infamous IMS bearing—a tiny part that can grenade your entire engine.
Suddenly, buying a used 911 came with the same level of anxiety as dating a Hollywood starlet.
Still… it’s got a flat-six. Rear-engine. Manual gearbox. And now it’s the cheapest way into the 911 club.
So does it suck? Yeah. Do we love it anyway? Also yeah.
Would you risk it?

"""
  story_messages = [
    {"role": "user", "content": prompt},
  ]

  response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=story_messages,
    temperature=1.9,
    max_tokens=1000,
    top_p=0.90,
    frequency_penalty=1.2,
    n=1
  )

  story = response.choices[0].message.content

  return story

"""# Text to Speech"""

def text2speech(story):
    # Clean and split story into valid sentences
    sentences = [s.strip() for s in story.replace("\n", " ").split(".") if s.strip()]

    print(sentences)

    # List to store audio segments and durations
    audio_segments = []
    durations = []

    # Directory for audio output
    dir_path = "audio"
    if os.path.exists(dir_path):
        shutil.rmtree(dir_path)
    os.mkdir(dir_path)

    # randomly select voice
    voice_list = ["alloy", "echo", "fable", "onyx", "nova", "shimmer"]
    voice = random.choice(voice_list)

    for i, sentence in enumerate(sentences[:-1]):
        response = client.audio.speech.create(
            model="tts-1",
            voice=voice,
            input=sentence
        )

        # Save the audio response
        response.stream_to_file(f"{dir_path}/audio_{i}.mp3")

        # Load the audio file to calculate the duration
        audio = AudioSegment.from_mp3(f"{dir_path}/audio_{i}.mp3")
        durations.append(audio.duration_seconds)
        audio_segments.append(audio)

    # Combine all audio segments
    combined_audio = sum(audio_segments)

    # Save combined audio as WAV
    combined_audio.export("combined_output.wav", format="wav")

    # Return the durations for syncing with images
    return durations

"""# Image Generation"""

from PIL import Image

def resize_and_crop(image, target_width, target_height):
    # Calculate aspect ratios
    img_ratio = image.width / image.height
    target_ratio = target_width / target_height

    # Resize image
    if img_ratio > target_ratio:
        new_height = target_height
        new_width = int(img_ratio * new_height)
    else:
        new_width = target_width
        new_height = int(new_width / img_ratio)

    image = image.resize((new_width, new_height), resample=Image.LANCZOS)

    # Crop the center
    left = (new_width - target_width) // 2
    top = (new_height - target_height) // 2
    right = left + target_width
    bottom = top + target_height

    return image.crop((left, top, right, bottom))

def text2image(car, count=10, target_size=(1280, 1280), preview=True): #target_size=(1280, 720)
    import random
    import time
    import os
    import requests
    import matplotlib.pyplot as plt
    from PIL import Image
    from io import BytesIO
    from duckduckgo_search import DDGS
    import numpy as np
    import cv2

    dir_path = "images"
    if os.path.exists(dir_path):
        shutil.rmtree(dir_path)
    os.mkdir(dir_path)

    search_templates = [
        "{car} front angle", "{car} rear view", "{car} side profile", "{car} driving",
        "{car} interior", "{car} engine bay", "{car} wheels closeup",
        "{car} headlight closeup", "{car} taillight closeup", "{car} racing on road",
        "{car} drifting", "{car} mountain road", "{car} city streets",
        "{car} car show", "{car} dealership photo", "{car} outdoor photo", "{car} garage photo"
    ]
    random.shuffle(search_templates)

    image_paths = []
    with DDGS() as ddgs:
        for i, template in enumerate(search_templates):
            if len(image_paths) >= count:
                break

            query = template.format(car=car)
            print(f"Searching for: {query}")

            try:
                results = ddgs.images(query, max_results=5)
                for result in results:
                    try:
                        img_url = result["image"]
                        print(f"Attempting: {img_url}")

                        headers = {"User-Agent": "Mozilla/5.0"}
                        response = requests.get(img_url, headers=headers, timeout=5)
                        image = Image.open(BytesIO(response.content)).convert("RGB")
                        image = resize_and_crop(image, *target_size)

                        if preview:
                            plt.imshow(image)
                            plt.axis("off")
                            plt.show()

                        arr = np.array(image)
                        print("Array shape:", arr.shape, "Dtype:", arr.dtype)

                        bgr_img = cv2.cvtColor(arr, cv2.COLOR_RGB2BGR)
                        image_path = f"{dir_path}/image_{len(image_paths)}.jpg"
                        cv2.imwrite(image_path, bgr_img)
                        image_paths.append(image_path)
                        break  # Success, stop trying more URLs for this template

                    except Exception as e:
                        print(f"Skipping bad image: {e}")
                        continue
                time.sleep(1.5)
            except Exception as e:
                print(f"Error during search: {e}")
                time.sleep(3)

    if not image_paths:
        raise RuntimeError("No valid images were downloaded.")

    return image_paths

"""# Create Video"""

from moviepy.video.VideoClip import ImageClip
from moviepy.audio.io.AudioFileClip import AudioFileClip
from moviepy.video.compositing.CompositeVideoClip import CompositeVideoClip

def create_video(images, durations, index):
    images = images[:len(durations)]
    print(len(images), len(durations))
    assert len(images) == len(durations), "Number of images must match durations"

    video_clips = []

    for img_path, duration in zip(images, durations):
        clip = ImageClip(img_path).with_duration(duration)
        video_clips.append(clip)

    # Stack clips end-to-end manually
    current_start = 0
    positioned_clips = []
    for clip, duration in zip(video_clips, durations):
        positioned_clips.append(clip.with_start(current_start))
        current_start += duration

    # Create composite video (video only, no audio yet)
    video = CompositeVideoClip(positioned_clips)

    # Load audio
    audio = AudioFileClip("combined_output.wav")

    # Attach audio
    video = video.with_audio(audio)

    # Write to file with QuickTime compatibility
    output_path = f"{index}.mp4"
    video.write_videofile(
        output_path,
        codec="libx264",
        audio_codec="aac",
        fps=1,
        ffmpeg_params=["-movflags", "+faststart"]
    )

    return output_path

def send_email(num=0):

  # Initialize the yagmail SMTP client
  receiver_email = "mattafrank2439@gmail.com"  # Replace with your email
  sender_email = "mattafrank2439@gmail.com"    # Replace with your email
  app_password = userdata.get("EMAIL")         # Replace with your email app password

  # Compose the email
  subject = "File Attachment from Google Colab"
  body = "Please find the attached file."

  # Attach the file (make sure the file is in your Colab environment)
  file_path = f"{num}.mp4"  # Update this with your file path

  # Initialize yagmail client
  yag = yagmail.SMTP(sender_email, app_password)

  # Send the email with the attachment
  yag.send(
    to=receiver_email,
    subject=subject,
    contents=body,
    attachments=file_path,
  )

  print("Email sent successfully!")









for i in range(0, 5):
    try:
        idea = get_story_idea()  # already a dict
        car = idea["car"]
        concept = idea["concept"]
        print("Concept:", concept)
        print("Car:", car)

        story = get_story(concept)
        print("Story:", story)

        durations = text2speech(story)
        images = text2image(car)

        create_video(images, durations, car)
        send_email(car)

    except Exception as e:
        print("Error processing video generation:")
        print("Exception:", e)
        print("Idea:", idea)











# Disconnect runtime once everything is done
from google.colab import runtime
runtime.unassign()

from google.colab import files
files.download('output_video.mp4')

